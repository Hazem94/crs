{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_analysis\n",
    "import os\n",
    "from shutil import copy\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "Functions Defintions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0_label: suitable for children\n",
    "# 1_label: not suitable for children \n",
    "\n",
    "def get_percentage_of_labeled_data(labeled_0_words_count, labeled_1_words_count):\n",
    "    \"\"\"\n",
    "    Funtion to get the percentage of a labeled dataset out of the total corpus\n",
    "    :param labeled_0_words_count: count of words in label_0 docs\n",
    "    :param labeled_1_words_count: count of words in label_1 docs\n",
    "    :return: percentage_labeled_0, percentage_labeled_1\n",
    "    \"\"\"\n",
    "    total = labeled_0_words_count + labeled_1_words_count\n",
    "    return float(\"%.3f\" % (labeled_0_words_count / total)), \\\n",
    "           float(\"%.3f\" % (labeled_1_words_count / total))\n",
    "\n",
    "\n",
    "def get_average_docs_length(docs_info_lst):\n",
    "    \"\"\"\n",
    "    Function to get the average length of 0, 1 labeled docs in terms of words\n",
    "    :param docs_info_lst: lst of tuples of the form [(words_count, movie_id, rating), ..]\n",
    "    :return: average_docs_length \n",
    "    \"\"\"\n",
    "    total = 0\n",
    "    for file in docs_info_lst:\n",
    "        total += file[0]\n",
    "    return int(total / len(docs_info_lst))\n",
    "\n",
    "\n",
    "def get_dict_of_words_totalCount_docsCount(data_dictionary, label):\n",
    "    \"\"\" \n",
    "    Function to make a dict that represents words in each labeled data\n",
    "    :param data_dictionary: dict of the form {\"label_#: {\"movie_id\": [\"w_0\", \"w_1\", ...]}, .. }\n",
    "           label: string, 0_label or 1_label\n",
    "    :return: words_dict: a dict of the form: \n",
    "                        {word_0: [number_of_total_occurrence_in_a_labeled_data, \n",
    "                                 {movie_0: [number_of_occurrence_in_movie_0, \n",
    "                                  ... }\n",
    "                                ]\n",
    "                         ...\n",
    "                         }         \n",
    "    \"\"\"\n",
    "    words_dict = {}\n",
    "    # For each movie\n",
    "    for movie_name in data_dictionary[label]:\n",
    "        # For each word in this movie\n",
    "        for word in data_dictionary[label][movie_name]:\n",
    "            # If word is already exists in the dict\n",
    "            if word in words_dict:\n",
    "                # Increase the count of this word in teh total count among all docs\n",
    "                words_dict[word][0] += 1\n",
    "\n",
    "                # Increasing the count of this word in each doc, \"{movie_0: [doc_1_count, ..], ..}\"\n",
    "                if movie_name in words_dict[word][1]:\n",
    "                    #\n",
    "                    (words_dict[word][1])[movie_name] += 1\n",
    "                else:\n",
    "                    # Initialize\n",
    "                    (words_dict[word][1])[movie_name] = 1\n",
    "            # If word is not found in the dict before, initialize\n",
    "            else:\n",
    "                words_dict[word] = [1, {movie_name: 1}]\n",
    "    return words_dict\n",
    "\n",
    "def out_pickle(pickle_path, pick_name, variable_name):\n",
    "    \"\"\"\n",
    "    Function that pickles out a variable\n",
    "    :param pickle_path: in pickle's path\n",
    "    :param pick_name: in pickle's name 'without .pkl extension'\n",
    "    :param variable_name: the variable to be pickled out\n",
    "    :return: nothing\n",
    "    \"\"\"\n",
    "    with open(pickle_path + pick_name + \".pkl\", \"wb\") as pkl:\n",
    "        pickle.dump(variable_name, pkl)\n",
    "\n",
    "def in_pickle(pickle_path, pick_name):\n",
    "    \"\"\"\n",
    "    Function that pickles in a variable\n",
    "    :param pickle_path: in pickle's path\n",
    "    :param pick_name: in pickle's name 'without .pkl extension'\n",
    "    :return: the variable that contains pickled in data\n",
    "    \"\"\"\n",
    "    with open(pickle_path + pick_name + \".pkl\", \"rb\") as pkl:\n",
    "        return pickle.load(pkl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.97 s, sys: 976 ms, total: 4.95 s\nWall time: 4.98 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# {\"label_#: {\"movie_id\": [\"w_0\", \"w_1\", ...]}, .. }\n",
    "data_dictionary = in_pickle('data/', 'all_labels_dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pandas_dict = {}\n",
    "\n",
    "pandas_dict[\"rating\"] = []\n",
    "pandas_dict [\"movie_id\"] = []\n",
    "pandas_dict [\"movie_words\"] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.03 ms, sys: 504 Âµs, total: 2.53 ms\nWall time: 2.54 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for label in list(data_dictionary.keys())[:2]:\n",
    "    for movie_name in data_dictionary[label]:\n",
    "        pandas_dict[\"rating\"].append(label)\n",
    "        pandas_dict[\"movie_words\"].append(data_dictionary[label][movie_name])\n",
    "        pandas_dict[\"movie_id\"].append(movie_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# row: index\n",
    "# columns : rating, movie_id, [word_1, word_2, ...]\n",
    "data_frames = pd.DataFrame(data=pandas_dict,\n",
    "                           columns=[\"rating\", \"movie_id\", \"movie_words\"])"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "Pickling out the data_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.18 s, sys: 892 ms, total: 9.07 s\nWall time: 10.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "out_pickle('data/', 'all_labels_dict', data_dictionary)"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "Pickling out the pandas_data_frames object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_pickle('data/', 'pandas_data_frame', data_frames)"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "Loading the pandas_data_frame pickle object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frames = in_pickle('data/', 'pandas_data_frame')"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "Loading the W2V model as a picke object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "pickle_in = open('C:/Users/Abdo/Project/pickle_files/word2vec_model_trained_150.pkl','rb')\n",
    "model = pickle.load(pickle_in)\n",
    "'''"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "Extracting the information from data_frame into a list of tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wCount_movieId_rating_lst: list of tuples: [ (words_count, movie_id, rating), ..... ] of the corpus \"both labels\"\n",
    "wordCount_movieId_rating_lst = []\n",
    "\n",
    "for index, row in data_frames.iterrows():\n",
    "    movie_id = row[\"movie_id\"]\n",
    "    rating = row[\"rating\"]\n",
    "    length = len(row[\"movie_words\"])\n",
    "    wordCount_movieId_rating_lst.append((length, movie_id, rating))\n",
    "    wordCount_movieId_rating_lst.sort()"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {
    "collapsed": false
   },
   "level": 1,
   "source": [
    "Data Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'print(pd.DataFrame(data=wordCount_movieId_rating_lst, \\n                   columns=[\"wordCount\", \"movieId\", \"rating\"]))\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of 0 & 1 labeled docs\n",
    "number_of_0_label_docs = len(data_dictionary[\"0_label\"])\n",
    "number_of_1_label_docs = len(data_dictionary[\"1_label\"])\n",
    "\n",
    "# percentage of 0, 1 labeled docs among the whole corpus\n",
    "percentage_0_labeled_docs, percentage_1_labeled_docs = \\\n",
    "    get_percentage_of_labeled_data(number_of_0_label_docs, number_of_1_label_docs)\n",
    "\n",
    "# find the max, and min number of words among all documents\n",
    "min_number_of_words = wordCount_movieId_rating_lst[0]\n",
    "max_number_of_words = wordCount_movieId_rating_lst[-1]\n",
    "\n",
    "# average docs length in terms of words \n",
    "average_docs_length = get_average_docs_length(wordCount_movieId_rating_lst)\n",
    "\n",
    "(number_of_0_label_docs,\n",
    " number_of_1_label_docs, \n",
    " percentage_0_labeled_docs,\n",
    " percentage_1_labeled_docs,\n",
    " average_docs_length)\n",
    "'''print(pd.DataFrame(data=wordCount_movieId_rating_lst, \n",
    "                   columns=[\"wordCount\", \"movieId\", \"rating\"]))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# from the word2vec model\\nvocabulary = set(model.wv.vocab)\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# from the word2vec model\n",
    "vocabulary = set(model.wv.vocab)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict of both 0, 1 labeled data\n",
    "dict_of_1_label_words = get_dict_of_words_totalCount_docsCount(data_dictionary, \"1_label\")\n",
    "dict_of_0_label_words = get_dict_of_words_totalCount_docsCount(data_dictionary, \"0_label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_0_keys = list(dict_of_0_label_words.keys())\n",
    "label_1_keys = list(dict_of_1_label_words.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76587, 148973)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(label_0_keys), len(label_1_keys))"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "Pickles out both 0 & 1 dict_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_pickle('data/', 'dict_of_1_label_words', dict_of_1_label_words)\n",
    "out_pickle('data/', 'dict_of_0_label_words', dict_of_0_label_words)"
   ]
  },
  {
   "cell_type": "heading",
   "metadata": {},
   "level": 1,
   "source": [
    "Load words_dict of 0 & 1 labels from pickles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.52 s, sys: 43.6 ms, total: 2.56 s\nWall time: 2.58 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dict_of_1_label_words = in_pickle('data/', 'dict_of_1_label_words')\n",
    "dict_of_0_label_words = in_pickle('data/', 'dict_of_0_label_words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "inappropriate_words = []\n",
    "# key : inappropriate_word\n",
    "#value : [total_occurences, {movie_id: occurenes_in_movie,movie_id: occurenes_in_movie,.....}]\n",
    "inappropriate_words_in_0_label_movies = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"C:/Users/Abdo/Project/Notes/inappropriate_words.txt\",\"r\")\n",
    "for word in file.readlines():\n",
    "    inappropriate_words.append(word.replace(\"\\n\",\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill the values \n",
    "for inappropriate_word in inappropriate_words:\n",
    "    if inappropriate_word in dict_of_0_label_words:\n",
    "        inappropriate_words_in_0_label_movies[inappropriate_word] = dict_of_0_label_words[inappropriate_word]\n",
    "    else:\n",
    "        inappropriate_words_in_0_label_movies[inappropriate_word] = [0,[]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('C:/Users/Abdo/Project/pickle_files/inappropriate_words_in_0_label_movies.pkl', 'wb') as output:\n",
    "    #pickle.dump(inappropriate_words_in_0_label_movies, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle_in = open('C:/Users/Abdo/Project/pickle_files/inappropriate_words_in_0_label_movies.pkl','rb')\n",
    "#inappropriate_words_in_0_label_movies = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#total_words_in_all_movies\n",
    "all_text_words = set(dict_of_1_label_words.keys())\n",
    "all_text_words.update(set(dict_of_0_label_words.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_words = set(dict_of_1_label_words.keys()).intersection(set(dict_of_0_label_words.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage_of_common_words = len(common_words)/len(all_text_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_words_in_0_label = set(dict_of_0_label_words.keys()).difference(common_words)\n",
    "unique_words_in_1_label = set(dict_of_1_label_words.keys()).difference(common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# key : word\n",
    "# value : [ [total frequency, {movie_name: frequency_of_word_in_movie},..] , .... ] \n",
    "frequency_of_unique_words_in_0_label = {}\n",
    "frequency_of_unique_words_in_1_label = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "for movie_name in data_dictionary[\"0_label\"]:\n",
    "    for word in data_dictionary[\"0_label\"][movie_name]:\n",
    "        if word in unique_words_in_0_label:\n",
    "            if word in frequency_of_unique_words_in_0_label:\n",
    "                frequency_of_unique_words_in_0_label[word][0] = frequency_of_unique_words_in_0_label[word][0]+1\n",
    "                if movie_name in frequency_of_unique_words_in_0_label[word][1]:\n",
    "                    frequency_of_unique_words_in_0_label[word][1][movie_name] = \\\n",
    "                    frequency_of_unique_words_in_0_label[word][1][movie_name]+1\n",
    "                else:\n",
    "                    frequency_of_unique_words_in_0_label[word][1][movie_name] = 1\n",
    "            else:\n",
    "                frequency_of_unique_words_in_0_label[word] = [1, {movie_name:1}]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "for movie_name in data_dictionary[\"1_label\"]:\n",
    "    for word in data_dictionary[\"1_label\"][movie_name]:\n",
    "        if word in unique_words_in_1_label:\n",
    "            if word in frequency_of_unique_words_in_1_label:\n",
    "                frequency_of_unique_words_in_1_label[word][0] = frequency_of_unique_words_in_1_label[word][0]+1\n",
    "                if movie_name in frequency_of_unique_words_in_1_label[word][1]:\n",
    "                    frequency_of_unique_words_in_1_label[word][1][movie_name] = \\\n",
    "                    frequency_of_unique_words_in_1_label[word][1][movie_name]+1\n",
    "                else:\n",
    "                    frequency_of_unique_words_in_1_label[word][1][movie_name] = 1\n",
    "            else:\n",
    "                frequency_of_unique_words_in_1_label[word] = [1, {movie_name:1}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('C:/Users/Abdo/Project/pickle_files/frequency_of_unique_words_in_1_label.pkl', 'wb') as output:\n",
    "    #pickle.dump(frequency_of_unique_words_in_1_label, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('C:/Users/Abdo/Project/pickle_files/frequency_of_unique_words_in_0_label.pkl', 'wb') as output:\n",
    "    #pickle.dump(frequency_of_unique_words_in_0_label, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle_in = open('C:/Users/Abdo/Project/pickle_files/frequency_of_unique_words_in_0_label.pkl','rb')\n",
    "#frequency_of_unique_words_in_0_label = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pickle_in = open('C:/Users/Abdo/Project/pickle_files/frequency_of_unique_words_in_1_label.pkl','rb')\n",
    "#frequency_of_unique_words_in_1_label = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [(frequency, word), ....]\n",
    "list_of_uinque_0_label_words_and_frequencies = []\n",
    "list_of_uinque_1_label_words_and_frequencies = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in frequency_of_unique_words_in_0_label:\n",
    "    list_of_uinque_0_label_words_and_frequencies.append( (frequency_of_unique_words_in_0_label[word][0], word) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in frequency_of_unique_words_in_1_label:\n",
    "    list_of_uinque_1_label_words_and_frequencies.append( (frequency_of_unique_words_in_1_label[word][0], word) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_uinque_0_label_words_and_frequencies.sort()\n",
    "list_of_uinque_1_label_words_and_frequencies.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('C:/Users/Abdo/Project/pickle_files/list_of_uinque_0_label_words_and_frequencies.pkl', 'wb') as output:\n",
    "    #pickle.dump(list_of_uinque_0_label_words_and_frequencies, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('C:/Users/Abdo/Project/pickle_files/list_of_uinque_1_label_words_and_frequencies.pkl', 'wb') as output:\n",
    "    #pickle.dump(list_of_uinque_1_label_words_and_frequencies, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open('C:/Users/Abdo/Project/pickle_files/list_of_uinque_1_label_words_and_frequencies.pkl','rb')\n",
    "list_of_uinque_1_label_words_and_frequencies = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open('C:/Users/Abdo/Project/pickle_files/list_of_uinque_0_label_words_and_frequencies.pkl','rb')\n",
    "list_of_uinque_0_label_words_and_frequencies = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the percentage of bad words in every 0_labeled movie\n",
    "# key : movie_id\n",
    "# value : percentage_of_bad_words\n",
    "percentage_of_bad_words_in_0_labeld_movies = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "for movie_name in data_dictionary[\"0_label\"]:\n",
    "    movie_words_count = len(data_dictionary[\"0_label\"][movie_name])\n",
    "    number_of_bad_words = 0\n",
    "    for bad_word in inappropriate_words_in_0_label_movies:\n",
    "        if movie_name in inappropriate_words_in_0_label_movies[bad_word][1]:\n",
    "            number_of_bad_words = number_of_bad_words + \\\n",
    "            inappropriate_words_in_0_label_movies[bad_word][1][movie_name]\n",
    "    percentage_of_bad_words_in_0_labeld_movies[movie_name] = number_of_bad_words/movie_words_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('C:/Users/Abdo/Project/pickle_files/percentage_of_bad_words_in_0_labeld_movies.pkl', 'wb') as output:\n",
    "    #pickle.dump(percentage_of_bad_words_in_0_labeld_movies, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open('C:/Users/Abdo/Project/pickle_files/percentage_of_bad_words_in_0_labeld_movies.pkl','rb')\n",
    "percentage_of_bad_words_in_0_labeld_movies = pickle.load(pickle_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn the dictionary into list to sort it\n",
    "# [ (percentage_of_bad_words_in_movie, movie_name) ]\n",
    "percentage_of_bad_words_in_0_labeld_movies_list = []\n",
    "for movie_name in percentage_of_bad_words_in_0_labeld_movies:\n",
    "    percentage_of_bad_words_in_0_labeld_movies_list.append\\\n",
    "        ( (percentage_of_bad_words_in_0_labeld_movies[movie_name], movie_name) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentage_of_bad_words_in_0_labeld_movies_list.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.019112874143526866, 'PG_4918')\n"
     ]
    }
   ],
   "source": [
    "print(percentage_of_bad_words_in_0_labeld_movies_list[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
